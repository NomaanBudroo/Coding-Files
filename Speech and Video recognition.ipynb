{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839d594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please say something\n",
      "Recording done, processing\n",
      "Listening...\n",
      "Please say something\n",
      "Recording done, processing\n",
      "You said: stop\n",
      "Program stopped\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries\n",
    "import cv2\n",
    "import speech_recognition as sr\n",
    "import datetime\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#defining the detect faces function\n",
    "def detect_faces(frame, face_cascade):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    return faces\n",
    "\n",
    "# Define the filter functions\n",
    "def apply_grayscale(frame):\n",
    "    return cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def apply_red_filter(frame):\n",
    "    red_overlay = np.full_like(frame, (0, 0, 255), dtype=np.uint8)  # Create a red overlay\n",
    "    return cv2.addWeighted(frame, 1.0, red_overlay, 0.5, 0)  # Blend the overlay with the frame\n",
    "\n",
    "# Define the available filters\n",
    "FILTERS = {\n",
    "    \"grayscale\": apply_grayscale,\n",
    "    \"red\": apply_red_filter,\n",
    "}\n",
    "#specifing the image path\n",
    "image_path = 'C:/Users/nomaa/OneDrive/Desktop/nomaan1.jpg'\n",
    "\n",
    "#defining the recognize uploaded image function\n",
    "\n",
    "def recognize_uploaded_image(image_path, face_cascade, frame):#passing image path and face cascade and frame variables\n",
    "    faces = detect_faces(frame, face_cascade)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        cv2.putText(frame, \"Face not detected\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    else:\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"Image has been Recognized\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    # Resize the frame to a smaller size\n",
    "    resized_frame = cv2.resize(frame, (300, 300))  # Adjust the size as needed\n",
    "    \n",
    "    cv2.imshow('Face Detection', resized_frame)\n",
    "    cv2.waitKey(2000)\n",
    "    \n",
    "#defining play number game function\n",
    "def play_number_guessing_game(r, frame):\n",
    "    print(\"Welcome to the Number Guessing Game!\")\n",
    "    secret_number = random.randint(1, 100)\n",
    "    attempts = 0\n",
    "    max_attempts = 5\n",
    "    \n",
    "    #handling attempts\n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            with sr.Microphone() as source:\n",
    "                print(\"Please say your guess (between 1 and 100):\")\n",
    "                audio_text = r.listen(source, timeout=10)\n",
    "                print(\"Recording done, processing\")\n",
    "                \n",
    "            guess = int(r.recognize_google(audio_text, language=\"en-US\"))\n",
    "            attempts += 1\n",
    "\n",
    "            if guess < secret_number:\n",
    "                print(\"Too low! Try again.\")\n",
    "            elif guess > secret_number:\n",
    "                print(\"Too high! Try again.\")\n",
    "            else:\n",
    "                print(f\"Congratulations! You guessed the number {secret_number} in {attempts} attempts.\")\n",
    "                break\n",
    "        except (ValueError, sr.UnknownValueError):\n",
    "            print(\"Invalid input or could not recognize. Please try again.\")\n",
    "\n",
    "        display_attempts(frame, attempts, max_attempts)  # Pass 'frame' as the first argument\n",
    "\n",
    "    if attempts >= max_attempts:\n",
    "        print(f\"Sorry, you've reached the maximum number of attempts. The secret number was {secret_number}.\")#displaying message after running out of attempts\n",
    "\n",
    "def display_attempts(frame, attempts, max_attempts):\n",
    "    text_y_position = 70\n",
    "    cv2.putText(frame, f\"Attempts: {max_attempts - attempts}/{max_attempts}\", (10, text_y_position + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "def main(video_capture):\n",
    "    # Initialize the face cascade classifier\n",
    "    cascPath = 'haarcascade_frontalface_default.xml'\n",
    "    faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "    \n",
    "    # Initialize the speech recognizer\n",
    "    r = sr.Recognizer()\n",
    "    applying_red_filter = False\n",
    "    detect_face_start_time = None\n",
    "\n",
    "    while True:\n",
    "        # Capture a frame from the webcam\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        # Detect faces using the face cascade classifier\n",
    "        faces = detect_faces(frame, faceCascade)\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            \n",
    "        # Display the number of detected faces and current time\n",
    "        num_faces = len(faces)\n",
    "        cv2.putText(frame, f\"Detected Faces: {num_faces}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        cv2.putText(frame, f\"Time: {current_time}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        text_y_position = 70  # Initial Y position for text\n",
    "        \n",
    "        # Display the instructions based on the current state\n",
    "        if not applying_red_filter:\n",
    "            cv2.putText(frame, \"Say 'red' to Apply Red Filter\", (10, text_y_position), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "            text_y_position += 20  # Increase Y position for the next message\n",
    "\n",
    "        cv2.putText(frame, \"Say 'detectface' for face detection\", (10, text_y_position), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        text_y_position += 20\n",
    "        cv2.putText(frame, \"Say 'Start game' to play game\", (10, text_y_position), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        text_y_position += 20\n",
    "        cv2.putText(frame, \"Say 'screenshot' to take a picture\", (10, text_y_position), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "        \n",
    "        if detect_face_start_time is not None:\n",
    "            elapsed_time = (datetime.datetime.now() - detect_face_start_time).total_seconds()\n",
    "            if elapsed_time < 2:\n",
    "                cv2.putText(frame, \"Image has been Recognized\", (10, text_y_position + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            else:\n",
    "                detect_face_start_time = None  # Reset the start time when time limit exceeded\n",
    "                cv2.destroyWindow(\"Detect Face\")  # Close the \"Detect Face\" window\n",
    "        \n",
    "        # Display the frame with all the information\n",
    "        cv2.imshow('Face Detection', frame)\n",
    "        \n",
    "        # Listen for voice commands using the microphone\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Please say something\")\n",
    "            audio_text = r.listen(source, timeout=100)\n",
    "            print(\"Recording done, processing\")\n",
    "\n",
    "        try:\n",
    "            text = r.recognize_google(audio_text, language=\"en-US\")\n",
    "            print(\"You said: \" + text)\n",
    "            \n",
    "            # Check for recognized voice commands and perform corresponding actions\n",
    "            if text.lower() == \"detect face\":\n",
    "                frame = cv2.imread(image_path)  # Load the image\n",
    "                recognize_uploaded_image(image_path, faceCascade, frame)\n",
    "                \n",
    "            elif text.lower() == \"screenshot\":  # Check for \"screenshot\" command\n",
    "                screenshot_filename = f\"screenshot_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.png\"\n",
    "                cv2.imwrite(screenshot_filename, frame)  # Save the screenshot\n",
    "                print(f\"Screenshot saved as {screenshot_filename}\")\n",
    "                \n",
    "            elif text.lower() == \"red\":  # Check for \"red\" command\n",
    "                red_filtered_frame = apply_red_filter(frame)  # Apply red filter\n",
    "                cv2.imshow('Face Detection', red_filtered_frame)  # Update the frame with red filter\n",
    "                \n",
    "            elif text.lower() == \"start game\":\n",
    "                play_number_guessing_game(r, frame)  # Start the number guessing game\n",
    "                \n",
    "            elif text.lower() == \"stop\":#check for stop command\n",
    "                print(\"Program stopped\")#when detected display program stopped\n",
    "                break\n",
    "                \n",
    "                \n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Listening...\")\n",
    "        except sr.RequestError:\n",
    "            print(\"Sorry, there was an issue with the Google Speech Recognition service\")\n",
    "            \n",
    "        # Check for user input to quit the program\n",
    "        if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    # Release the video capture and close all windows\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the webcam video capture\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    video_capture.set(3, 640) #set width\n",
    "    video_capture.set(4, 480) #set height\n",
    "    main(video_capture) #start main program loop\n",
    "    video_capture.release() #release video capture\n",
    "    cv2.destroyAllWindows() #close all windowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a4bb38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
